{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELDwKHVSP4ad"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkx5ejEZP8Ok"
      },
      "source": [
        "This section comprises **model training**, **robust analysis**, and **model interaction**\n",
        "\n",
        "**Model Training** consists of the following steps:\n",
        "\n",
        "- Tokenization\n",
        "- Padding\n",
        "- Train Test split\n",
        "- Model Training and Results\n",
        "\n",
        "**Robust Analysis** \n",
        "\n",
        "This section has two purposes:\n",
        "\n",
        "1. Check if the model understands simple concepts of monetary policy (content).\n",
        "\n",
        "2. Observe the model's prediction in a variety of texts taken from the real world.\n",
        "\n",
        "**Model Interaction (Only on notebook)**\n",
        "\n",
        "This section allows the user to input any sentence and observe the model's prediction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlUGxKvOmusf"
      },
      "source": [
        "## GPU Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wz8CNRDmwU0"
      },
      "source": [
        "To speed up model training, a GPU needs to be used.\n",
        "\n",
        "Go to Runtime -> Change Runtime type -> GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLmPD7e2PVjt"
      },
      "source": [
        "## SpaCy Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PRmE0aPbO8Iq",
        "outputId": "22377860-b870-49a5-85ff-0e76b93c52e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nPLEASE FOLLOW INSTRUCTIONS ON THIS CELL BEFORE RUNNING THIS NOTEBOOK.\\n'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "PLEASE FOLLOW INSTRUCTIONS ON THIS CELL BEFORE RUNNING THIS NOTEBOOK.\n",
        "\"\"\"\n",
        "\n",
        "# In order for this file to work, this cell needs to be run first\n",
        "# Remove the '#' on the last two lines and run the cell.\n",
        "# When it is done the Runtime needs to be restarted at Runtime -> Restart Runtime\n",
        "# Please make the last two lines adding '#' at the beginning.\n",
        "# Please wait until ALL commands have run\n",
        "\n",
        "#!pip install spacy --upgrade\n",
        "#!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35fkv3OoP1CV"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KkUPONVYQ9Fk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ynOcNkaGUG3C"
      },
      "outputs": [],
      "source": [
        "# Random seed to guarantee that the results can be reproduced.\n",
        "tf.keras.utils.set_random_seed(25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MenrykD5VxQM"
      },
      "source": [
        "## Getting the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGgJSLUBV2KQ",
        "outputId": "e4d007d9-d6cb-487b-faae-ba999de821e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'central_bank_thesis'...\n",
            "remote: Enumerating objects: 311, done.\u001b[K\n",
            "remote: Counting objects: 100% (204/204), done.\u001b[K\n",
            "remote: Compressing objects: 100% (186/186), done.\u001b[K\n",
            "remote: Total 311 (delta 15), reused 135 (delta 6), pack-reused 107\u001b[K\n",
            "Receiving objects: 100% (311/311), 17.08 MiB | 10.95 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ],
      "source": [
        "# Get files from github repository\n",
        "!git clone https://github.com/luissejas/central_bank_thesis.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2B21-VtWjvd"
      },
      "source": [
        "# 5.3.3 Tokenization and Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jwRDGpXsWoNL"
      },
      "outputs": [],
      "source": [
        "# Load the prepared dataset\n",
        "raw_dataset = pd.read_csv('/content/central_bank_thesis/gru_model/balanced_dataset.csv')\n",
        "raw_dataset.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "\n",
        "# Splitting the features (text) and the labels (classification)\n",
        "raw_text = raw_dataset['text'].values.tolist()\n",
        "label = raw_dataset['label'].values.tolist()\n",
        "\n",
        "# Once the text goes through tokenization and padding, its datatype will become an np array\n",
        "# Therefore, we convert the label from list -> np array to avoid problems when feeding the data into the model\n",
        "label_as_array = np.asarray(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p3cwSVtsZx8K"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL\n",
        "# Visualize the raw text before tokenization\n",
        "#raw_text[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-Dt_6IHkXhj9"
      },
      "outputs": [],
      "source": [
        "# Load the Tokenizer and tokenize each word.\n",
        "# Note that this will only create a reference for each word as shown in the diagram\n",
        "# These lines of code will not 'translate' the raw text into tokens\n",
        "\n",
        "# Create an instance of the tokenizer\n",
        "tokenizer = Tokenizer(num_words=13000, split=' ')\n",
        "\n",
        "# Create the references from the raw text\n",
        "tokenizer.fit_on_texts(raw_text)\n",
        "\n",
        "# Substitute the raw text into tokens\n",
        "# Observe the raw text has not been replaced, but a 'translated copy' was created\n",
        "tokenized_text = tokenizer.texts_to_sequences(raw_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nhJjOE_gZVHl"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL\n",
        "# Visualize the raw text after tokenization\n",
        "#tokenized_text[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uPmmT6HualEW"
      },
      "outputs": [],
      "source": [
        "# Pad the sequence\n",
        "padded_tokenized_text = pad_sequences(tokenized_text, maxlen=72, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IYyGaIN_a54k"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL\n",
        "# Visualize the text after padding\n",
        "#padded_tokenized_text[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjuEhveTb0Kv"
      },
      "source": [
        "# 5.4 Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H3d7JnbcmcW"
      },
      "source": [
        "Now that the data is prepared to be fed into the model, other parts need to be setup for the model to begin training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFuGeoG6ddK-"
      },
      "source": [
        "## 5.4.1 Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOLdqjOKd_rm"
      },
      "source": [
        "For this thesis, Tensorflow's Keras API is utilized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BjG-LwllgSSO"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL\n",
        "# This cell keeps the original version, in case the user wants to try out different architectures.\n",
        "\n",
        "#from tensorflow.keras import Model\n",
        "#from tensorflow.keras.layers import Dense, Embedding, SpatialDropout1D, Input, GRU\n",
        "\n",
        "#inputs = Input(shape=(72,))\n",
        "#embedding_layer = Embedding(13000, 150, input_length=72)(inputs)\n",
        "#dropout_1 = SpatialDropout1D(0.35)(embedding_layer)\n",
        "#gru_layer = GRU(150)(dropout_1)\n",
        "#out_layer = Dense(1, activation='sigmoid')(gru_layer)\n",
        "\n",
        "#model = Model(inputs=inputs, outputs=out_layer, name=\"gru_classifier\")\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4o_XTo6b44K",
        "outputId": "7b8200fb-fb3f-4d96-918a-b0ea39998441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"gru_classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 72)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 72, 150)           1950000   \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 72, 150)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 150)               135900    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 151       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,086,051\n",
            "Trainable params: 2,086,051\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, SpatialDropout1D, Input, GRU\n",
        "\n",
        "# Neural Network Architecture (Functional method)\n",
        "inputs = Input(shape=(72,))\n",
        "embedding_layer = Embedding(13000, 150, input_length=72)(inputs)\n",
        "dropout_1 = SpatialDropout1D(0.35)(embedding_layer)\n",
        "gru_layer = GRU(150)(dropout_1)\n",
        "out_layer = Dense(1, activation='sigmoid')(gru_layer)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=out_layer, name=\"gru_classifier\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_aNIZZyemgN"
      },
      "source": [
        "## 5.4.2 Training Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b8Ktl3pfQaF"
      },
      "source": [
        "### Model Compilation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mS0G4HvEe0ZN"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL\n",
        "# This cell keeps the original version, in case the user wants to try out different architectures.\n",
        "\n",
        "#from tensorflow.keras.losses import BinaryCrossentropy\n",
        "#from tensorflow.keras.metrics import BinaryAccuracy\n",
        "#from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Compiling the model\n",
        "#loss = BinaryCrossentropy(from_logits=False)\n",
        "#metric = BinaryAccuracy(name='accuracy')\n",
        "#optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "#model.compile(optimizer=optimizer, loss=loss, metrics=metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "r1tHOv9ceuaq"
      },
      "outputs": [],
      "source": [
        "# Compiling the model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "loss = BinaryCrossentropy(from_logits=False)\n",
        "metric = BinaryAccuracy(name='accuracy')\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKaPJT1JfPKl"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yUAQuuKNfVKk"
      },
      "outputs": [],
      "source": [
        "# Train Test Split\n",
        "# Splitting the data into training and test data\n",
        "# Random state kept only for the purpose of code reproduction.\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(padded_tokenized_text, label_as_array, test_size=0.2, random_state=35)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9KFd7rrf3FW",
        "outputId": "6d029e8c-9314-4fcb-df74-7a8b3ed62d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "777/777 [==============================] - 16s 11ms/step - loss: 0.5975 - accuracy: 0.6559 - val_loss: 0.4594 - val_accuracy: 0.7934\n",
            "Epoch 2/2\n",
            "777/777 [==============================] - 8s 10ms/step - loss: 0.4075 - accuracy: 0.8218 - val_loss: 0.4162 - val_accuracy: 0.8124\n"
          ]
        }
      ],
      "source": [
        "# Begin model training\n",
        "history = model.fit(x_train, y_train, epochs=2, batch_size=32, validation_data = (x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNwWZ2T3kQhm"
      },
      "source": [
        "# 6.2 Robustness Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_zVxpVykafW"
      },
      "source": [
        "As mentioned earlier, this section evaluates the model on two metrics: content and source. \n",
        "\n",
        "It comprised three sections:\n",
        "\n",
        "0. Functions\n",
        "\n",
        "  Functions to help the reader focus only on the output and not on the preprocessing.\n",
        "\n",
        "1. Content\n",
        "\n",
        "  Some classic terms associated with prosperity and adversity economic periods will be fed into the model and the model's prediction will be analyzed.\n",
        "\n",
        "2. Source\n",
        "\n",
        "  Text from different sources but from in sample time periods will be classified by the model. Then the results will be analyzed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dST_z-gnnY3e"
      },
      "source": [
        "## 6.2.0 Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GTiTUVtGp1iI"
      },
      "outputs": [],
      "source": [
        "# Preparing SpaCy\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# POS list\n",
        "pos_list = pos_list = ['ADJ', 'ADV', 'VERB', 'NOUN']\n",
        "\n",
        "# Preparing Vocabulary\n",
        "vocabulary_as_csv = pd.read_csv('/content/central_bank_thesis/gru_model/vocabulary.csv')\n",
        "vocabulary = vocabulary_as_csv['word'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "72DmvbL9nJ15"
      },
      "outputs": [],
      "source": [
        "def output_raw_text_model_prediction(raw_text: str, nlp, pos_list: list, vocabulary: list, tokenizer, model):\n",
        "  \"\"\"\n",
        "  Steps:\n",
        "    1) Filter the words according to the vocabulary\n",
        "\n",
        "    2) Tokenize and pad raw text\n",
        "\n",
        "    3) Predict economic period\n",
        "\n",
        "    4) Output predicted label\n",
        "  \"\"\"\n",
        "  # Step 1)\n",
        "\n",
        "  raw_text_doc, filtered_words_list = nlp(raw_text), []\n",
        "\n",
        "  for token in raw_text_doc:\n",
        "    if token.pos_ in pos_list and token.lemma_ in vocabulary:\n",
        "      filtered_words_list.append(token.lemma_)\n",
        "  \n",
        "  filtered_text = [' '.join(filtered_words_list)]\n",
        "\n",
        "  # Step 2\n",
        "  tokenized_text = tokenizer.texts_to_sequences(filtered_text)\n",
        "  padded_tokenized_text = pad_sequences(tokenized_text, maxlen=72, padding='post')\n",
        "\n",
        "  # Step 3\n",
        "  # Activation function is sigmoid function\n",
        "  # 1 if the result is over 0.5, 0 otherwise\n",
        "  raw_prediction = (model.predict(padded_tokenized_text) > 0.5).astype('int32')\n",
        "\n",
        "  # Step 4\n",
        "  # The prediction output needs to be transformed to get only its value\n",
        "\n",
        "  model_prediction_unformatted = raw_prediction.tolist()\n",
        "  model_prediction = [output[0] for output in model_prediction_unformatted]\n",
        "\n",
        "  if model_prediction[0]:\n",
        "    prediction_label = \"Prosperity\"\n",
        "  else:\n",
        "    prediction_label = \"Adversity\"\n",
        "\n",
        "  return prediction_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_XzD9FmzgAh"
      },
      "source": [
        "## 6.2.1 Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdVbwrQY8yUg"
      },
      "source": [
        "In this section, some theoretical knowledge of monetary policy is tested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZqiV94hzisX"
      },
      "source": [
        "### Example 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RSav8wcGuVvQ"
      },
      "outputs": [],
      "source": [
        "text_ = \"I believe that high inflation will persist throughout this period.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZvqPfHzyuh6W",
        "outputId": "5f693f4c-d615-4d13-fb48-7ab7c6cdde9d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Adversity'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_output = output_raw_text_model_prediction(\n",
        "    raw_text=text_,\n",
        "    nlp=nlp,\n",
        "    pos_list=pos_list,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer = tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "example_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "No1GcIEBzruB"
      },
      "outputs": [],
      "source": [
        "text_ = \"In my view, the current inflation rate is transitory.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aL1oOPFKzsYm",
        "outputId": "d5ff7dcc-7d91-4922-df75-06df54bbf6a1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Prosperity'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_output = output_raw_text_model_prediction(\n",
        "    raw_text=text_,\n",
        "    nlp=nlp,\n",
        "    pos_list=pos_list,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer = tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "example_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74z-5mDw0HUA"
      },
      "source": [
        "### Example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NBjeNzlw0JGZ"
      },
      "outputs": [],
      "source": [
        "text_ = \"Lowering the interest rate to stimulate the economy.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c3QCih8S0JuA",
        "outputId": "286bfc72-d001-4bef-a049-13005eadef95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Prosperity'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_output = output_raw_text_model_prediction(\n",
        "    raw_text=text_,\n",
        "    nlp=nlp,\n",
        "    pos_list=pos_list,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer = tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "example_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6uZMUxrC3234"
      },
      "outputs": [],
      "source": [
        "text_ = \"We raise the interest rate to cool down prices.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pcWrIa2f32n4",
        "outputId": "35f94e0d-75e8-4109-d09f-eda5459bbdf6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Adversity'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_output = output_raw_text_model_prediction(\n",
        "    raw_text=text_,\n",
        "    nlp=nlp,\n",
        "    pos_list=pos_list,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer = tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "example_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADXWryCv73Ga"
      },
      "source": [
        "### 6.2.2 Real World Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwO8IO5F9MIG"
      },
      "source": [
        "In this section, I use the model to classify real world text from different sources.\n",
        "\n",
        "The idea is to test whether the model understand announcements about the economy in simple language.\n",
        "\n",
        "Additionally, I test whether the model works on different styles of speech."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl-VLwi6-KkX"
      },
      "source": [
        "### Example 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIqpMCBh-NZr"
      },
      "source": [
        "Janet Yellen interview with CNBC in 2017\n",
        "\n",
        "Source: https://www.cnbc.com/2017/12/13/yellens-only-regret-as-fed-chair-low-inflation.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8Fs8gb_87-DM"
      },
      "outputs": [],
      "source": [
        "# Normal Language\n",
        "text_ = \"I feel good about the economy outlook, I feel good that the labor market is in a very much stronger place than it was eight years ago. We’ve created 17 million jobs, we’ve got a good, strong labor market and a very low unemployment rate. That’s been tremendously important to the well-being of American households and workers.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8kT-FExC-bYa",
        "outputId": "b73ce11b-9e4e-4ee9-abce-2de2cb791899"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Prosperity'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_output = output_raw_text_model_prediction(\n",
        "    raw_text=text_,\n",
        "    nlp=nlp,\n",
        "    pos_list=pos_list,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer = tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "example_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "aSBBlwR8-gap"
      },
      "outputs": [],
      "source": [
        "# Technical Language\n",
        "text_ = \"We have a 2 percent symmetric inflation objective. For a number of years now, inflation has been running under 2 percent, and I consider it an important priority to make sure that inflation doesn’t chronically undershoot our 2 percent objective.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v72lQ263ADaQ",
        "outputId": "9292358c-620c-4dae-ee26-4f8027aa56ed"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Prosperity'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_output = output_raw_text_model_prediction(\n",
        "    raw_text=text_,\n",
        "    nlp=nlp,\n",
        "    pos_list=pos_list,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer = tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "example_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJG2yA5tA134"
      },
      "source": [
        "### Example 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbaapXYoA6Dh"
      },
      "source": [
        "Excerpt from Mario Draghi's (European Central Bank) speech\n",
        "\n",
        "Source: https://www.ecb.europa.eu/press/key/date/2012/html/sp120726.en.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "V0vUZEVwAEkh"
      },
      "outputs": [],
      "source": [
        "# Talk during Euro crisis\n",
        "text_ = \"The progress in undertaking deficit control, structural reforms has been remarkable. And they will have to continue to do so. But the pace has been set and all the signals that we get is that they don’t relent, stop reforming themselves. It’s a complex process because for many years, very little was done – I will come to this in a moment.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6ui9q3oRBKeD",
        "outputId": "17764b72-495e-4324-eeee-bfaea7206fde"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Prosperity'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_output = output_raw_text_model_prediction(\n",
        "    raw_text=text_,\n",
        "    nlp=nlp,\n",
        "    pos_list=pos_list,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer = tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "example_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoP6w6XgChHo"
      },
      "source": [
        "### Example 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTWmsbdfR6Kv"
      },
      "source": [
        "FOMC Statement 28 June 2000\n",
        "\n",
        "Source: https://fraser.stlouisfed.org/title/federal-open-market-committee-meeting-minutes-transcripts-documents-677/meeting-june-27-28-2000-23199/content/pdf/20000628statement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jdgpHkQZBNL0"
      },
      "outputs": [],
      "source": [
        "text_ = \"The Federal Open Market Committee at its meeting today decided to maintain the existing stance of monetary policy, keeping its target for the federal funds rate at 6-1/2 percent. Recent data suggest that the expansion of aggregate demand may be moderating toward a pace closer to the rate of growth of the economy's potential to produce. Although core measures of prices are rising slightly faster than a year ago, continuing rapid advances in productivity have been containing costs and holding down underlying price pressures. Nonetheless, signs that growth in demand is moving to a sustainable pace are still tentative and preliminary, and the utilization of the pool of available workers remains at an unusually high level. In these circumstances, and against the background of its long-term goals of price stability and sustainable economic growth and of the information currently available, the Committee believes the risks continue to be weighted mainly toward conditions that may generate heightened inflation pressures in the foreseeable future.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lat9W52HRzH4",
        "outputId": "336082fc-4605-4ac2-e996-45e7e669ed42"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Adversity'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_output = output_raw_text_model_prediction(\n",
        "    raw_text=text_,\n",
        "    nlp=nlp,\n",
        "    pos_list=pos_list,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer = tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "example_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv3WVcDPSyKn"
      },
      "source": [
        "## 6.2.3 Try it Yourself"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duFZLR6lS1mQ"
      },
      "source": [
        "In this section the user can input any text and see the model's prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tZjIokbkSxkB"
      },
      "outputs": [],
      "source": [
        "text_ = \"INSERT YOUR SENTENCE HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TefvUBGTTBBv"
      },
      "outputs": [],
      "source": [
        "example_output = output_raw_text_model_prediction(\n",
        "    raw_text=text_,\n",
        "    nlp=nlp,\n",
        "    pos_list=pos_list,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer = tokenizer,\n",
        "    model=model\n",
        ")\n",
        "\n",
        "example_output"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "2_2_model_training_robust_analysis.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
